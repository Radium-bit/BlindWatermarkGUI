# V3算法的候选流程-rc1：技术总结

本文档旨在对V3版本的鲁棒二进制信息嵌入算法的候选流程（`rc1`）进行技术性总结。该算法的核心目标是将任意二进制数据（如文本字符串）编码成一个具有高鲁棒性的布尔值比特流，以便嵌入到各种媒介中，并能从可能存在噪声或数据丢失的比特流中准确地解码恢复出原始信息。

此版本修复了早期实现中的CRC校验、同步模式匹配及数据包提取逻辑等关键问题。

## 1\. 核心数据结构

算法的核心是\*\*数据包（Packet）\*\*的结构设计。最终生成的比特流由一系列重复的数据包构成，每个数据包都包含了恢复完整信息所需的一部分数据和元数据。

一个完整的数据包序列在编码后形成一个**主比特流（Master Bitstream）**，该流会根据需要重复，以填充目标的嵌入容量。

### 数据包结构 (Packet Structure)

每个数据包由两部分组成：一个`16`位的**同步头**和一个`n`字节（默认为255字节）的**RS编码数据**。

```
+----------------------+-----------------------------------------+
|  同步头 (Sync Header) |        RS编码数据 (RS-Encoded Data)        |
|      (2 Bytes)       |               (n Bytes)                 |
+----------------------+-----------------------------------------+
```

### RS编码数据内部结构

`RS编码数据`是通过对一个`k`字节（默认为63字节）的数据块进行里德-所罗门（Reed-Solomon）前向纠错编码生成的。这个`k`字节的数据块由\*\*元数据（Metadata）**和**数据分片（Data Chunk）\*\*组成。

```
<-- k Bytes -->
+---------------------+-------------------+----------+
|  元数据 (Metadata)   |   数据分片 (Chunk)  |  填充... |
|     (10 Bytes)      |   (k - 10 Bytes)  | (Padding)|
+---------------------+-------------------+----------+
```

#### 元数据 (Metadata)

元数据区长度为`10`字节，包含了重组完整数据所需的所有关键信息，其结构如下（大端字节序）：

* **总载荷长度 (Total Payload Length)** - `4`字节：原始数据经过`zlib`压缩后的总字节数。
* **分片索引 (Chunk Index)** - `2`字节：当前数据分片在所有分片中的序号（从0开始）。
* **总分片数 (Total Chunks)** - `2`字节：数据被分割成的总分片数量。
* **元数据CRC (Header CRC)** - `2`字节：对前`8`个字节（总载荷长度、分片索引、总分片数）计算出的`CRC16-CCITT-FALSE`校验码，用于确保元数据的完整性。

这种自包含的设计使得解码器即使没有接收到第一个数据包，也能从任意一个有效的数据包中了解整个数据的宏观结构。

## 2\. 实现流程

算法的实现流程分为**编码**和**解码**两个主要阶段。

### 2.1 编码流程 (Encoding Process)

编码流程将原始数据（字符串或字节）转换为一个可用于嵌入的、带有冗余和纠错能力的布尔值列表。

1. **数据准备与压缩 (Preparation & Compression)**
   
   * 如果输入是字符串，首先使用`UTF-8`编码转换为字节。
   * 使用`zlib`库对字节数据进行高等级压缩（`level=9`），以减小需要编码的载荷大小。

2. **数据分片 (Chunking)**
   
   * 根据`RS(n, k)`的参数（默认为`RS(255, 63)`）和`10`字节的元数据大小，计算出每个数据包能容纳的有效数据分片大小，即 `k_data = k - 10`。
   * 将压缩后的数据按`k_data`的大小进行分割，计算出**总分片数（Total Chunks）**。

3. **数据包构建与编码 (Packet Construction & Encoding)**
   
   * 遍历每一个数据分片，执行以下操作：
     a.  **构建元数据**：创建`10`字节的元数据，填入压缩数据总长度、当前分片索引、总分片数，并计算前8字节的`CRC16-CCITT`校验码。
     b.  **组合数据**：将元数据与当前数据分片拼接。
     c.  **填充**：如果组合后的数据长度不足`k`字节，则用空字节（`\x00`）填充至`k`字节。
     d.  **RS编码**：使用`ReedSolomonEncoder`对这`k`字节的数据进行编码，生成一个`n`字节的纠错码块。
     e.  **添加同步头**：在`n`字节的纠错码块前，添加一个`16`位的同步头（默认为`0xB593`），形成一个完整的数据包。

4. **比特流生成与交织 (Bitstream Generation & Interleaving)**
   
   * 将所有生成的数据包依次拼接，并转换为一个布尔值列表，形成**主比特流**。
   * **交织（Interleaving）**：对主比特流进行按位交织处理。该过程将比特流重新排列，使得原始序列中连续的比特在交织后被分散开。这极大地增强了对\*\*突发错误（Burst Errors）\*\*的抵抗能力，因为一段连续的错误在去交织后会变成多个分散的、可被RS码纠正的单个错误。

5. **容量适配 (Capacity Adaptation)**
   
   * 如果指定了最大容量（`max_capacity_bits`），则重复主比特流，直到填满指定的容量。这种重复机制是鲁棒性的另一个关键来源，它确保了每个数据分片在最终的比特流中有多个副本。

### 2.2 解码流程 (Decoding Process)

解码流程负责从一个可能包含错误的比特流中，稳健地提取和重构原始数据。

1. **去交织 (De-interleaving)**
   
   * 对接收到的比特流首先进行**去交织**操作，恢复比特的原始顺序，将可能存在的突发错误分散化。

2. **同步头搜索 (Sync Header Search)**
   
   * 在整个去交织后的比特流中，搜索所有与`16`位同步头模式匹配的位置。由于比特流可能包含重复数据和噪声，这一步通常会找到多个候选的数据包起始位置。

3. **数据包提取与解码 (Packet Extraction & Decoding)**
   
   * 从每个找到的同步头位置开始，提取其后`n`字节长度的比特，构成一个候选的RS编码数据包。
   * 使用`ReedSolomonDecoder`对每个候选数据包尝试解码。`RS`解码器能够纠正一定数量的字节错误。

4. **元数据校验 (Metadata Validation)**
   
   * 对于每个成功通过`RS`解码的数据包，提取其前`10`字节的元数据。
   * 重新计算元数据前`8`字节的`CRC16`校验码，并与数据包中存储的第`9-10`字节的`CRC`值进行比较。
   * 只有`CRC`校验通过，该数据包才被视为**完全有效**。同时，还会对元数据中的数值进行合理性检查（如总长度、总分片数是否异常）。

5. **有效分片收集 (Valid Chunk Collection)**
   
   * 对于每个完全有效的数据包，根据其元数据中的**分片索引**，将解码出的数据分片（`chunk_data`）存储起来。
   * 使用一个字典（如`defaultdict(list)`）来收集所有属于同一索引的分片。由于编码时的数据重复，解码器可能会找到同一个分片的多个有效（但可能纠错数量不同）的版本。

6. **数据重组 (Data Reassembly)**
   
   * 从收集到的有效分片中，确定最终的**总载荷长度**和**总分片数**。
   * 遍历从`0`到`总分片数-1`的所有索引：
     a.  如果该索引存在一个或多个已恢复的分片，则选择其中“最好”的一个版本（当前代码实现选择**RS纠错数最少**的版本）作为最终数据。
     b.  如果某个索引的分片未能恢复，则数据重组失败（当前代码会用空字节填充，这通常会导致后续解压失败）。
   * 将所有最终选择的分片按顺序拼接，重构出完整的压缩数据。

7. **数据解压与输出 (Data Decompression & Output)**
   
   * 对重组后的压缩数据使用`zlib`进行解压。
   * 如果解压成功，将得到的字节数据用`UTF-8`解码成最终的文本字符串。

# 